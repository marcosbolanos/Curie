{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython import get_ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m     ccle_expression = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33msli-algo inputs/CCLE_Expression.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     ccle_expression = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msli-algo inputs/OmicsExpressionProteinCodingGenesTPMLogp1BatchCorrected_24Q2.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/io/parsers/readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/io/parsers/readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:2053\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:334\u001b[39m, in \u001b[36mgetstate\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "useNewData = True\n",
    "\n",
    "if useNewData == False:\n",
    "    ccle_expression = pd.read_csv(\"sli-algo inputs/CCLE_Expression.csv\")\n",
    "else:\n",
    "    ccle_expression = pd.read_csv(\"sli-algo inputs/OmicsExpressionProteinCodingGenesTPMLogp1BatchCorrected_24Q2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if useNewData == False:\n",
    "    gene_effect = pd.read_csv(\"sli-algo inputs/CRISPR_gene_effect.csv\")\n",
    "else:\n",
    "    gene_effect = pd.read_csv(\"sli-algo inputs/CRISPRGeneEffect_24Q2.csv\")\n",
    "\n",
    "gene_effect.rename(columns={gene_effect.columns[0]:\"DepMap_ID\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Convert CRISPR KO data to long format\u001b[39;00m\n\u001b[32m     11\u001b[39m crispr_long = gene_effect.melt(id_vars=\u001b[33m\"\u001b[39m\u001b[33mDepMap_ID\u001b[39m\u001b[33m\"\u001b[39m, var_name=\u001b[33m\"\u001b[39m\u001b[33mgene_name\u001b[39m\u001b[33m\"\u001b[39m, value_name=\u001b[33m\"\u001b[39m\u001b[33mcrispr_effect\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m crispr_long[\u001b[33m\"\u001b[39m\u001b[33mgene_name\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mcrispr_long\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgene_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m(.*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m final_table_pd = expr_long.merge(crispr_long, on=[\u001b[33m\"\u001b[39m\u001b[33mDepMap_ID\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgene_name\u001b[39m\u001b[33m\"\u001b[39m], how=\u001b[33m\"\u001b[39m\u001b[33mouter\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m#REVERSE SIGN of gene effect to make the biggest effect positive\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/core/strings/accessor.py:137\u001b[39m, in \u001b[36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    132\u001b[39m     msg = (\n\u001b[32m    133\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot use .str.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with values of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minferred dtype \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._inferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    135\u001b[39m     )\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/core/strings/accessor.py:1567\u001b[39m, in \u001b[36mStringMethods.replace\u001b[39m\u001b[34m(self, pat, repl, n, case, flags, regex)\u001b[39m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m case \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     case = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1567\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_str_replace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregex\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wrap_result(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/core/strings/object_array.py:179\u001b[39m, in \u001b[36mObjectStringArrayMixin._str_replace\u001b[39m\u001b[34m(self, pat, repl, n, case, flags, regex)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    177\u001b[39m     f = \u001b[38;5;28;01mlambda\u001b[39;00m x: x.replace(pat, repl, n)\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_str_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/core/strings/object_array.py:78\u001b[39m, in \u001b[36mObjectStringArrayMixin._str_map\u001b[39m\u001b[34m(self, f, na_value, dtype, convert)\u001b[39m\n\u001b[32m     76\u001b[39m map_convert = convert \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.all(mask)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     result = \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_convert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# Reraise the exception if callable `f` got wrong number of args.\u001b[39;00m\n\u001b[32m     81\u001b[39m     \u001b[38;5;66;03m# The user may want to be warned by this, instead of getting NaN\u001b[39;00m\n\u001b[32m     82\u001b[39m     p_err = (\n\u001b[32m     83\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m((takes)|(missing)) (?(2)from \u001b[39m\u001b[33m\\\u001b[39m\u001b[33md+ to )?\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md+ \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     84\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(?(3)required )positional arguments?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     85\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2895\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer_mask\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2932\u001b[39m, in \u001b[36mpandas._libs.lib._map_infer_mask\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/core/strings/object_array.py:175\u001b[39m, in \u001b[36mObjectStringArrayMixin._str_replace.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    172\u001b[39m         pat = re.compile(pat, flags=flags)\n\u001b[32m    174\u001b[39m     n = n \u001b[38;5;28;01mif\u001b[39;00m n >= \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     f = \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mpat\u001b[49m\u001b[43m.\u001b[49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    177\u001b[39m     f = \u001b[38;5;28;01mlambda\u001b[39;00m x: x.replace(pat, repl, n)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Rename the first column of the DataFrame (since Dask is lazy, we need to get the list of column names first)\n",
    "column_names = list(ccle_expression.columns)\n",
    "ccle_expression = ccle_expression.rename(columns={column_names[0]: \"DepMap_ID\"})\n",
    "\n",
    "# Convert expression data to long format\n",
    "expr_long = ccle_expression.melt(id_vars=\"DepMap_ID\", var_name=\"gene_name\", value_name=\"gene_expression\")\n",
    "\n",
    "expr_long[\"gene_name\"] = expr_long[\"gene_name\"].str.replace(r\" \\(.*\", \"\", regex=True)\n",
    "\n",
    "# Convert CRISPR KO data to long format\n",
    "crispr_long = gene_effect.melt(id_vars=\"DepMap_ID\", var_name=\"gene_name\", value_name=\"crispr_effect\")\n",
    "\n",
    "crispr_long[\"gene_name\"] = crispr_long[\"gene_name\"].str.replace(r\" \\(.*\", \"\", regex=True)\n",
    "\n",
    "final_table_pd = expr_long.merge(crispr_long, on=[\"DepMap_ID\", \"gene_name\"], how=\"outer\")\n",
    "\n",
    "#REVERSE SIGN of gene effect to make the biggest effect positive\n",
    "final_table_pd[\"crispr_effect\"] = -final_table_pd[\"crispr_effect\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving as csv so we can clear the memory\n",
    "final_table = final_table_pd\n",
    "final_table.to_csv(\"sli-algo outputs/final_table_newdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting all variables from memory so we can improve performance of later code\n",
    "%reset -sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Once the data has been preprocessed, the script can effectively start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from scipy.stats import mannwhitneyu \n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "final_table = pd.read_csv(\"sli-algo outputs/final_table_newdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data into a dictionary for quick accessstatsmodels\n",
    "gene_groups = {gene: group for gene, group in final_table.groupby('gene_name')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_populations(mutant_data, lower_percentile, upper_percentile):\n",
    "    gene_expr = mutant_data['gene_expression'].values\n",
    "    low_bound = np.percentile(gene_expr, lower_percentile)\n",
    "    high_bound = np.percentile(gene_expr, upper_percentile)\n",
    "    \n",
    "    mask_low = gene_expr <= low_bound\n",
    "    mask_high = gene_expr > high_bound\n",
    "    \n",
    "    population = np.where(mask_low, 'low', np.where(mask_high, 'high', None))\n",
    "    mutant_data = mutant_data.assign(population=population)\n",
    "    return mutant_data.dropna(subset=['population'])\n",
    "\n",
    "def one_sided_test(mutant, data, gene):\n",
    "    data = data.drop_duplicates(subset=[\"DepMap_ID\", \"gene_name\", \"crispr_effect\", \"population\"])\n",
    "    if data.empty or data[\"population\"].nunique() < 2:\n",
    "        return None\n",
    "    \n",
    "    counts = data[\"population\"].value_counts()\n",
    "    high_count = counts.get(\"high\", 0)\n",
    "    low_count = counts.get(\"low\", 0)\n",
    "    if high_count == 0 or low_count == 0:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        stat, p_value = mannwhitneyu(\n",
    "            data[data[\"population\"] == \"low\"][\"crispr_effect\"],\n",
    "            data[data[\"population\"] == \"high\"][\"crispr_effect\"],\n",
    "            alternative='less',\n",
    "            method='asymptotic'\n",
    "        )\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "    result = {\n",
    "        \"mutant\": mutant,\n",
    "        \"gene\": gene,\n",
    "        \"high\": high_count,\n",
    "        \"low\": low_count,\n",
    "        \"p_value\": p_value,\n",
    "        \"statistic\": stat,\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "def run_hypothesis_test_unique_percentiles(mutant, gene, low_percentile, high_percentile):\n",
    "    # Fetch CRISPR data\n",
    "    crispr_data = gene_groups[gene].dropna(subset=['crispr_effect'])\n",
    "    if crispr_data.empty:\n",
    "        return create_empty_result(mutant, gene, low_percentile, high_percentile)\n",
    "    \n",
    "    # Fetch mutant data \n",
    "    mutant_data = gene_groups.get(mutant, pd.DataFrame())\n",
    "    # Filter it to eliminate entries that aren't in CRISPR_data \n",
    "    mutant_data = mutant_data[mutant_data['DepMap_ID'].isin(crispr_data['DepMap_ID'])].dropna(subset=['gene_expression'])\n",
    "    if mutant_data.empty:\n",
    "        return create_empty_result(mutant, gene, low_percentile, high_percentile)\n",
    "    \n",
    "    # 3. Split populations\n",
    "    expression_populations = split_populations(mutant_data, low_percentile, high_percentile)\n",
    "    if expression_populations.empty:\n",
    "        return create_empty_result(mutant, gene, low_percentile, high_percentile)\n",
    "    \n",
    "    # 4. Map population to CRISPR data\n",
    "    population_map = expression_populations.set_index('DepMap_ID')['population']\n",
    "    crispr_population_data = crispr_data[crispr_data['DepMap_ID'].isin(population_map.index)].copy()\n",
    "    crispr_population_data['population'] = crispr_population_data['DepMap_ID'].map(population_map)\n",
    "    crispr_population_data.dropna(subset=['population'], inplace=True)\n",
    "    \n",
    "    # 5. Compute mean/median differences\n",
    "    mean_median = crispr_population_data.groupby('population')['crispr_effect'].agg(['mean', 'median']).diff().fillna(0)\n",
    "    diff_mean = mean_median['mean'].iloc[-1]\n",
    "    diff_median = mean_median['median'].iloc[-1]\n",
    "    \n",
    "    # 6. Perform test\n",
    "    result = one_sided_test(mutant, crispr_population_data, gene)\n",
    "    if result is None:\n",
    "        return create_empty_result(mutant, gene, low_percentile, high_percentile)\n",
    "    \n",
    "    result['low_percentile'] = low_percentile\n",
    "    result['high_percentile'] = high_percentile\n",
    "    result['diff_mean'] = diff_mean\n",
    "    result['diff_median'] = diff_median\n",
    "    return result\n",
    "\n",
    "def create_empty_result(mutant, gene, low, high):\n",
    "    result = {\n",
    "        \"mutant\": [mutant],\n",
    "        \"gene\": [gene],\n",
    "        \"high\": [0],\n",
    "        \"low\": [0],\n",
    "        \"p_value\": [np.nan],\n",
    "        \"statistic\": [np.nan],\n",
    "        \"low_percentile\": [low],\n",
    "        \"high_percentile\": [high],\n",
    "        \"diff_mean\": [0],\n",
    "        \"diff_median\": [0]\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to Excel file with one tab for each mutant\n",
    "def save_results_to_excel(results_df, filename=\"sli-algo outputs/results.xlsx\"):\n",
    "    # Create Excel writer\n",
    "    with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
    "        # Create a sheet with all results\n",
    "        # First convert adjusted_p_value to float for proper sorting\n",
    "        if 'adjusted_p_value' in results_df.columns:\n",
    "            # Create a temporary float column for sorting\n",
    "            results_df['adjusted_p_value_float'] = results_df['adjusted_p_value'].apply(lambda x: float(x) if pd.notna(x) else float('inf'))\n",
    "            # Sort the entire dataframe by mutant and then by p-value\n",
    "            all_results = results_df.sort_values(by=['mutant', 'adjusted_p_value_float'])\n",
    "            # Remove the float column\n",
    "            all_results = all_results.drop(columns=['adjusted_p_value_float'])\n",
    "        else:\n",
    "            all_results = results_df\n",
    "            \n",
    "        # Save all results to first sheet\n",
    "        all_results.to_excel(writer, sheet_name='All_Results', index=False)\n",
    "        \n",
    "        # Create separate sheets for each mutant\n",
    "        for mutant in results_df['mutant'].unique():\n",
    "            # Filter data for this mutant\n",
    "            mutant_data = results_df[results_df['mutant'] == mutant]\n",
    "            \n",
    "            # Sort by p-value numerically (ascending)\n",
    "            if 'adjusted_p_value' in mutant_data.columns:\n",
    "                # Create a temporary float column for sorting\n",
    "                mutant_data['adjusted_p_value_float'] = mutant_data['adjusted_p_value'].apply(\n",
    "                    lambda x: float(x) if pd.notna(x) else float('inf'))\n",
    "                # Sort by the numerical p-value\n",
    "                mutant_data = mutant_data.sort_values(by='adjusted_p_value_float')\n",
    "                # Remove the temporary float column\n",
    "                mutant_data = mutant_data.drop(columns=['adjusted_p_value_float'])\n",
    "            \n",
    "            # Save to sheet named with the mutant's name\n",
    "            mutant_data.to_excel(writer, sheet_name=f'{mutant}', index=False)\n",
    "        \n",
    "        # Fix openpyxl bug: ensure all sheets are marked as visible before saving\n",
    "        for ws in writer.book.worksheets:\n",
    "            ws.sheet_state = 'visible'\n",
    "            \n",
    "    print(f\"Results saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the process_row function at module level for multiprocessing to work\n",
    "def process_row(row):\n",
    "    return run_hypothesis_test_unique_percentiles(\n",
    "        row[\"mutant\"], row[\"gene\"], row[\"low_percentile\"], row[\"high_percentile\"]\n",
    "    )\n",
    "\n",
    "def run_crispr_database(mutants_to_include, ko_genes_to_include, low_percentile, high_percentile, threads=1):  \n",
    "    # Create a list of all SL pairs to be tested (excluding self-pairs)\n",
    "    mutant_gene_pairs = [(mutant, ko_gene, low_percentile, high_percentile)\n",
    "             for mutant in mutants_to_include\n",
    "             for ko_gene in ko_genes_to_include if ko_gene != mutant]\n",
    "    \n",
    "    # Convert the list of tuples into a DataFrame\n",
    "    mutant_gene_pairs_df = pd.DataFrame(mutant_gene_pairs, columns=[\"mutant\", \"gene\", \"low_percentile\", \"high_percentile\"])\n",
    "\n",
    "    # Single-threaded execution\n",
    "    if threads == 1:\n",
    "        results = mutant_gene_pairs_df.apply(\n",
    "            lambda row: run_hypothesis_test_unique_percentiles(\n",
    "                row[\"mutant\"], row[\"gene\"], low_percentile, high_percentile\n",
    "            ), axis=1\n",
    "        )\n",
    "        results_df = results.apply(pd.Series)\n",
    "    \n",
    "    elif threads > 1:\n",
    "        # Convert DataFrame to list of dictionaries for multiprocessing\n",
    "        rows = mutant_gene_pairs_df.to_dict('records')\n",
    "    \n",
    "        # Create a pool of workers\n",
    "        with multiprocessing.Pool(processes=threads) as pool:\n",
    "            # Map the function to the rows\n",
    "            results_list = pool.map(process_row, rows)\n",
    "        \n",
    "        # Convert the list of results to a DataFrame\n",
    "        results_df = pd.DataFrame(results_list)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Invalid number of threads\")\n",
    "\n",
    "    # Apply Benjamini-Hochberg correction to p-values\n",
    "    for mutant in mutants_to_include: \n",
    "        p_values = results_df.loc[results_df['mutant'] == mutant, 'p_value'].values\n",
    "        reject, corrected_p_values, _, _ = multipletests(p_values, method='fdr_bh')\n",
    "        results_df.loc[results_df['mutant'] == mutant, 'adjusted_p_value'] = corrected_p_values\n",
    "\n",
    "    # Format adjusted p-values in scientific notation\n",
    "    results_df['adjusted_p_value'] = results_df['adjusted_p_value'].apply(lambda x: f\"{x:.6E}\")\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: SFTA3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-4:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     10\u001b[39m mutants_to_include = [\u001b[33m\"\u001b[39m\u001b[33mARID1A\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mARID1B\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mARID2\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mBAP1\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mCREBBP\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mEED\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mKMT2C\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mKMT2D\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mPBRM1\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mSETD2\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mSMARCA2\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mSMARCA4\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mSMARCB1\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# mutants_to_include = [\"ARID1A\"]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m results_df = \u001b[43mrun_crispr_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmutants_to_include\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mko_genes_to_include\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m90\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m results_df\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mrun_crispr_database\u001b[39m\u001b[34m(mutants_to_include, ko_genes_to_include, low_percentile, high_percentile, threads)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Create a pool of workers\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m multiprocessing.Pool(processes=threads) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Map the function to the rows\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     results_list = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Convert the list of results to a DataFrame\u001b[39;00m\n\u001b[32m     35\u001b[39m results_df = pd.DataFrame(results_list)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/multiprocessing/pool.py:367\u001b[39m, in \u001b[36mPool.map\u001b[39m\u001b[34m(self, func, iterable, chunksize)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    363\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[33;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[33;03m    in a list that is returned.\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/multiprocessing/pool.py:768\u001b[39m, in \u001b[36mApplyResult.get\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    769\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ready():\n\u001b[32m    770\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/multiprocessing/pool.py:765\u001b[39m, in \u001b[36mApplyResult.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/threading.py:659\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    657\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# this is the list of KO genes that are to be tested for each mutant, it contains 10053 rows\n",
    "\n",
    "ko_genes_to_include = pd.read_excel('sli-algo inputs/reactome genes list (to include).xlsx')['gene_name'].to_list()\n",
    "\n",
    "# We make sure that all of the genes are incuded in our dataset, otherwise, we drop it and print it out\n",
    "ko_genes_to_include = [gene for gene in ko_genes_to_include if gene in gene_groups or print(\"Removed:\", gene)]\n",
    "\n",
    "# And this is the list of mutant genes that are to be tested\n",
    "\n",
    "mutants_to_include = [\"ARID1A\",\"ARID1B\",\"ARID2\",\"BAP1\",\"CREBBP\",\"EED\",\"KMT2C\",\"KMT2D\",\"PBRM1\",\"SETD2\",\"SMARCA2\",\"SMARCA4\",\"SMARCB1\"]\n",
    "\n",
    "# mutants_to_include = [\"ARID1A\"]\n",
    "\n",
    "results_df = run_crispr_database(mutants_to_include, ko_genes_to_include, 10, 90, threads = 6)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "At least one sheet must be visible",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/core/arrays/categorical.py:460\u001b[39m, in \u001b[36mCategorical.__init__\u001b[39m\u001b[34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     codes, categories = \u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/core/algorithms.py:795\u001b[39m, in \u001b[36mfactorize\u001b[39m\u001b[34m(values, sort, use_na_sentinel, size_hint)\u001b[39m\n\u001b[32m    793\u001b[39m             values = np.where(null_mask, na_value, values)\n\u001b[32m--> \u001b[39m\u001b[32m795\u001b[39m     codes, uniques = \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/core/algorithms.py:595\u001b[39m, in \u001b[36mfactorize_array\u001b[39m\u001b[34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[39m\n\u001b[32m    594\u001b[39m table = hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m uniques, codes = \u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7281\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7195\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'list'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36msave_results_to_excel\u001b[39m\u001b[34m(results_df, filename)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Sort the entire dataframe by mutant and then by p-value\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m all_results = \u001b[43mresults_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmutant\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43madjusted_p_value_float\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Remove the float column\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/core/frame.py:7183\u001b[39m, in \u001b[36mDataFrame.sort_values\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7178\u001b[39m         keys = [\n\u001b[32m   7179\u001b[39m             Series(k, name=name)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   7180\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m (k, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(keys, by)\n\u001b[32m   7181\u001b[39m         ]\n\u001b[32m-> \u001b[39m\u001b[32m7183\u001b[39m     indexer = \u001b[43mlexsort_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   7184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\n\u001b[32m   7185\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7186\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(by):\n\u001b[32m   7187\u001b[39m     \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/core/sorting.py:351\u001b[39m, in \u001b[36mlexsort_indexer\u001b[39m\u001b[34m(keys, orders, na_position, key, codes_given)\u001b[39m\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     cat = \u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mordered\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    352\u001b[39m     codes = cat.codes\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/core/arrays/categorical.py:462\u001b[39m, in \u001b[36mCategorical.__init__\u001b[39m\u001b[34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     codes, categories = \u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype.ordered:\n\u001b[32m    464\u001b[39m         \u001b[38;5;66;03m# raise, as we don't have a sortable data structure and so\u001b[39;00m\n\u001b[32m    465\u001b[39m         \u001b[38;5;66;03m# the user should give us one by specifying categories\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/core/algorithms.py:795\u001b[39m, in \u001b[36mfactorize\u001b[39m\u001b[34m(values, sort, use_na_sentinel, size_hint)\u001b[39m\n\u001b[32m    793\u001b[39m             values = np.where(null_mask, na_value, values)\n\u001b[32m--> \u001b[39m\u001b[32m795\u001b[39m     codes, uniques = \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/core/algorithms.py:595\u001b[39m, in \u001b[36mfactorize_array\u001b[39m\u001b[34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[39m\n\u001b[32m    594\u001b[39m table = hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m uniques, codes = \u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7281\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7195\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'list'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Save results to Excel file\u001b[39;00m\n\u001b[32m      2\u001b[39m filename = \u001b[33m\"\u001b[39m\u001b[33msli-algo outputs/results_newdata.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43msave_results_to_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36msave_results_to_excel\u001b[39m\u001b[34m(results_df, filename)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave_results_to_excel\u001b[39m(results_df, filename=\u001b[33m\"\u001b[39m\u001b[33msli-algo outputs/results.xlsx\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# Create Excel writer\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m pd.ExcelWriter(filename, engine=\u001b[33m'\u001b[39m\u001b[33mopenpyxl\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[32m      5\u001b[39m         \u001b[38;5;66;03m# Create a sheet with all results\u001b[39;00m\n\u001b[32m      6\u001b[39m         \u001b[38;5;66;03m# First convert adjusted_p_value to float for proper sorting\u001b[39;00m\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33madjusted_p_value\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m results_df.columns:\n\u001b[32m      8\u001b[39m             \u001b[38;5;66;03m# Create a temporary float column for sorting\u001b[39;00m\n\u001b[32m      9\u001b[39m             results_df[\u001b[33m'\u001b[39m\u001b[33madjusted_p_value_float\u001b[39m\u001b[33m'\u001b[39m] = results_df[\u001b[33m'\u001b[39m\u001b[33madjusted_p_value\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mif\u001b[39;00m pd.notna(x) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/io/excel/_base.py:1353\u001b[39m, in \u001b[36mExcelWriter.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\n\u001b[32m   1348\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1349\u001b[39m     exc_type: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mBaseException\u001b[39;00m] | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1350\u001b[39m     exc_value: \u001b[38;5;167;01mBaseException\u001b[39;00m | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1351\u001b[39m     traceback: TracebackType | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1352\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1353\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/io/excel/_base.py:1357\u001b[39m, in \u001b[36mExcelWriter.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1355\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1356\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"synonym for save, to make it more file-like\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1357\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1358\u001b[39m     \u001b[38;5;28mself\u001b[39m._handles.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/pandas/io/excel/_openpyxl.py:110\u001b[39m, in \u001b[36mOpenpyxlWriter._save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_save\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    107\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03m    Save workbook to disk.\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._handles.handle, mmap.mmap):\n\u001b[32m    112\u001b[39m         \u001b[38;5;66;03m# truncate file to the written content\u001b[39;00m\n\u001b[32m    113\u001b[39m         \u001b[38;5;28mself\u001b[39m._handles.handle.truncate()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/openpyxl/workbook/workbook.py:386\u001b[39m, in \u001b[36mWorkbook.save\u001b[39m\u001b[34m(self, filename)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.write_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.worksheets:\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m.create_sheet()\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[43msave_workbook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/openpyxl/writer/excel.py:294\u001b[39m, in \u001b[36msave_workbook\u001b[39m\u001b[34m(workbook, filename)\u001b[39m\n\u001b[32m    292\u001b[39m workbook.properties.modified = datetime.datetime.now(tz=datetime.timezone.utc).replace(tzinfo=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    293\u001b[39m writer = ExcelWriter(workbook, archive)\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/openpyxl/writer/excel.py:275\u001b[39m, in \u001b[36mExcelWriter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    274\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Write data into the archive.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28mself\u001b[39m._archive.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/openpyxl/writer/excel.py:89\u001b[39m, in \u001b[36mExcelWriter.write_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     87\u001b[39m writer = WorkbookWriter(\u001b[38;5;28mself\u001b[39m.workbook)\n\u001b[32m     88\u001b[39m archive.writestr(ARC_ROOT_RELS, writer.write_root_rels())\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m archive.writestr(ARC_WORKBOOK, \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     90\u001b[39m archive.writestr(ARC_WORKBOOK_RELS, writer.write_rels())\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m._merge_vba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/openpyxl/workbook/_writer.py:150\u001b[39m, in \u001b[36mWorkbookWriter.write\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28mself\u001b[39m.write_names()\n\u001b[32m    149\u001b[39m \u001b[38;5;28mself\u001b[39m.write_pivots()\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_views\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28mself\u001b[39m.write_refs()\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tostring(\u001b[38;5;28mself\u001b[39m.package.to_tree())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/openpyxl/workbook/_writer.py:137\u001b[39m, in \u001b[36mWorkbookWriter.write_views\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrite_views\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     active = \u001b[43mget_active_sheet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.wb.views:\n\u001b[32m    139\u001b[39m         \u001b[38;5;28mself\u001b[39m.wb.views[\u001b[32m0\u001b[39m].activeTab = active\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/home/marcos/Code/bioinfo/Marcos/synlethdb-benchmark2/.venv/lib64/python3.13/site-packages/openpyxl/workbook/_writer.py:35\u001b[39m, in \u001b[36mget_active_sheet\u001b[39m\u001b[34m(wb)\u001b[39m\n\u001b[32m     33\u001b[39m visible_sheets = [idx \u001b[38;5;28;01mfor\u001b[39;00m idx, sheet \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(wb._sheets) \u001b[38;5;28;01mif\u001b[39;00m sheet.sheet_state == \u001b[33m\"\u001b[39m\u001b[33mvisible\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m visible_sheets:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAt least one sheet must be visible\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m idx = wb._active_sheet_index\n\u001b[32m     38\u001b[39m sheet = wb.active\n",
      "\u001b[31mIndexError\u001b[39m: At least one sheet must be visible"
     ]
    }
   ],
   "source": [
    "# Save results to Excel file\n",
    "filename = \"sli-algo outputs/results_python.csv\"\n",
    "results_df.to_csv(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
